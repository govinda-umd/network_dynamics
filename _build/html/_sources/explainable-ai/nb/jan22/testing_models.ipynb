{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561af485-e9bd-42a7-afe6-a17c7979db85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# January 27-30, 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208e90c2-fbc9-48ab-9f66-41024f3852b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/govindas/venvs/expln-ai3.9/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.9.0-dev20220124). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pickle \n",
    "\n",
    "import shap\n",
    "\n",
    "# main dirs\n",
    "proj_dir = pjoin(os.environ['HOME'], 'explainable-ai')\n",
    "\n",
    "# folders\n",
    "sys.path.insert(0, proj_dir)\n",
    "from helpers.dataset_utils import *\n",
    "from helpers.base_model import *\n",
    "from helpers.model_definitions import *\n",
    "\n",
    "# select the GPU to be used\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd049c5e-4c4a-4803-8a0e-996b36b6a38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fb6dd4-0c81-4438-a91b-59f27c6e8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 18:54:32.032533: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-29 18:54:32.475220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14796 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = Linear_Model()\n",
    "\n",
    "default_slice = lambda x, start, end : x[start : end, ...]\n",
    "\n",
    "linear_regression = base_model(task_type=\"regression\", \n",
    "                               model=model, \n",
    "                               loss_object=tf.keras.losses.MeanSquaredError(), \n",
    "                               L1_scale=0.0, \n",
    "                               L2_scale=0.0,\n",
    "                               optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                               eval_metric=tfa.metrics.RSquare(),\n",
    "                               eval_metric_name=\"% var explained\",\n",
    "                               batch_size=32, \n",
    "                               slice_input=default_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020499ef-abb1-44f6-a539-bbda337643bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d52b4ee-9bbe-4904-b938-d52c9c1a5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "with open(pjoin(proj_dir, 'data/emoprox2', 'train_test_arrays.pkl'), 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "# converting to tf tensors\n",
    "data_dict['train'] = to_tensor(data_dict['train'])\n",
    "data_dict['test'] = to_tensor(data_dict['test'])\n",
    "\n",
    "# get inputs, targets and masks\n",
    "train_X = data_dict['train'][0]\n",
    "train_y = data_dict['train'][1]\n",
    "train_mask = data_dict['train'][2]\n",
    "\n",
    "test_X = data_dict['test'][0]\n",
    "test_y = data_dict['test'][1]\n",
    "test_mask = data_dict['test'][2]\n",
    "\n",
    "# mask the tensors\n",
    "train_X = train_X * tf.expand_dims(tf.cast(train_mask, 'float32'), -1)\n",
    "train_y = train_y * tf.cast(train_mask, 'float32')\n",
    "\n",
    "test_X = test_X * tf.expand_dims(tf.cast(test_mask, 'float32'), -1)\n",
    "test_y = test_y * tf.cast(test_mask, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98892781-34ee-4d8c-b3fa-3e5a72ade289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([647, 360, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.cast(train_mask, 'float32'), -1).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7544297e-7015-440e-8425-d6e5cc55e6d2",
   "metadata": {},
   "source": [
    "print('mask ----')\n",
    "mask = np.array([[True, False], [False, True]])\n",
    "mask = tf.convert_to_tensor(mask)\n",
    "print(mask.shape)\n",
    "print(mask)\n",
    "\n",
    "print('####')\n",
    "\n",
    "print('X ----')\n",
    "X = np.array([[[1.0, 2.0, 1.0], [2.0, 1.0, 2.0]], \n",
    "              [[3.0, 4.0, 3.0], [4.0, 3.0, 4.0]]])\n",
    "X = X * tf.expand_dims(tf.cast(mask, 'float32'), -1)\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "print('####')\n",
    "\n",
    "print('y ----')\n",
    "y = np.array([\n",
    "    [[1.0], [1.0]], \n",
    "    [[2.0], [2.0]]\n",
    "])\n",
    "y = y * tf.expand_dims(tf.cast(mask, 'float32'), -1)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "\n",
    "print('####')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d2520-7fb3-4e6a-9879-dfcb57672444",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b6385fe-2a33-45a6-9f86-84bc028d93cf",
   "metadata": {},
   "source": [
    "y_pred = linear_regression.model(X)\n",
    "\n",
    "# print(linear_regression.evaluate(X, y, False))\n",
    "# print(linear_regression.evaluate(X, y, True))\n",
    "# print(linear_regression.evaluate(X, y, False))\n",
    "# print(linear_regression.evaluate(X, y, True))\n",
    "\n",
    "# linear_regression.fit(train_X=X, train_Y=y, val_X=X, val_Y=y, num_epochs=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be9f969a-0215-4ae8-9db1-8056d3ede9ac",
   "metadata": {},
   "source": [
    "y_pred = linear_regression.model(train_X)\n",
    "\n",
    "print( linear_regression.evaluate(train_X, train_y, False) )\n",
    "print( linear_regression.evaluate(train_X, train_y, False) )\n",
    "print( linear_regression.evaluate(train_X, train_y, True) )\n",
    "print( linear_regression.evaluate(train_X, train_y, False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf7d64b-ddbc-4e6a-8ac6-ac869b215942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Train Loss: 0.065, Train % var explained: 5.607%  Val Loss: 0.064, Val % var explained: 6.339%  \n",
      "Epoch 001: Train Loss: 0.064, Train % var explained: 6.611%  Val Loss: 0.064, Val % var explained: 7.024%  \n",
      "Epoch 002: Train Loss: 0.064, Train % var explained: 6.995%  Val Loss: 0.063, Val % var explained: 7.224%  \n",
      "Epoch 003: Train Loss: 0.064, Train % var explained: 7.090%  Val Loss: 0.063, Val % var explained: 7.295%  \n",
      "Epoch 004: Train Loss: 0.064, Train % var explained: 7.097%  Val Loss: 0.063, Val % var explained: 7.291%  \n",
      "Epoch 005: Train Loss: 0.064, Train % var explained: 7.055%  Val Loss: 0.063, Val % var explained: 7.257%  \n",
      "Epoch 006: Train Loss: 0.064, Train % var explained: 6.969%  Val Loss: 0.063, Val % var explained: 7.207%  \n",
      "Epoch 007: Train Loss: 0.064, Train % var explained: 6.822%  Val Loss: 0.063, Val % var explained: 7.152%  \n",
      "Epoch 008: Train Loss: 0.064, Train % var explained: 6.582%  Val Loss: 0.064, Val % var explained: 7.097%  \n",
      "Epoch 009: Train Loss: 0.064, Train % var explained: 6.224%  Val Loss: 0.064, Val % var explained: 7.036%  \n",
      "Epoch 010: Train Loss: 0.065, Train % var explained: 5.769%  Val Loss: 0.064, Val % var explained: 6.973%  \n",
      "Epoch 011: Train Loss: 0.065, Train % var explained: 5.306%  Val Loss: 0.064, Val % var explained: 6.915%  \n",
      "Epoch 012: Train Loss: 0.065, Train % var explained: 4.984%  Val Loss: 0.064, Val % var explained: 6.847%  \n",
      "Epoch 013: Train Loss: 0.065, Train % var explained: 4.944%  Val Loss: 0.064, Val % var explained: 6.766%  \n",
      "Epoch 014: Train Loss: 0.065, Train % var explained: 5.192%  Val Loss: 0.064, Val % var explained: 6.726%  \n"
     ]
    }
   ],
   "source": [
    "results = linear_regression.fit(train_X=train_X, \n",
    "                                train_Y=train_y, \n",
    "                                val_X=train_X, \n",
    "                                val_Y=train_y, \n",
    "                                num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7116b-e36b-4a51-9962-6a0e6654e634",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shapley values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc4c4d3c-2a17-4ed8-b044-efa394d37ebe",
   "metadata": {},
   "source": [
    "# select a set of background examples to take an expectation over\n",
    "s = train_X.shape\n",
    "X = tf.reshape(train_X, shape=(s[0]*s[1], s[2])).numpy()\n",
    "X_background = shap.utils.sample(X, 100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9f1a504-b289-49bb-a1cb-4cadf5e8fa59",
   "metadata": {},
   "source": [
    "explainer = shap.KernelExplainer(model=linear_regression.model, \n",
    "                                 data=X_background)\n",
    "shap_values = explainer.shap_values(test_X[0, 0:1, :].numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2caf80ce-41dc-4ade-869f-51d505547363",
   "metadata": {},
   "source": [
    "shap_values.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
